{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "General guides: \n",
    "https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050\n",
    "\n",
    "Adit Deshpande (2016) - The 9 deep learning papers you need to know about (understanding CNNs part 3)\n",
    "https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html\n",
    "\n",
    "\n",
    "Example: http://scs.ryerson.ca/~aharley/vis/conv/flat.html\n",
    "\n",
    "<img src=\"files/CNNs.png\">\n",
    "\n",
    "\n",
    "Steps:\n",
    "1. Convolution\n",
    "2. Max Pooling\n",
    "3. Flattening\n",
    "4. Full Connection\n",
    "\n",
    "\n",
    "Yann Lecun (facebook) - godfather of CNN's\n",
    "\n",
    "eg Yann Lecun (1998) - Gradient-based learning applied to document recognition\n",
    "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "\n",
    "Math: \n",
    "Jianxin Wu (2017) - Introduction to Convolutional Neural Networks:\n",
    "https://pdfs.semanticscholar.org/450c/a19932fcef1ca6d0442cbf52fec38fb9d1e5.pdf\n",
    "\n",
    "\n",
    "#### What are Convolutional Neural Networks\n",
    "\n",
    "CNN's are networks that are used to classify images.\n",
    "Image = matrix of pixels;\n",
    "\n",
    "\n",
    "#### Convolution Operation\n",
    "\n",
    "Filters that are applied to images to detect certain features in an image.\n",
    "\n",
    "Convolution product:\n",
    "\n",
    "In general: $(f * g)(t) = \\int_{-inf}^{+inf} f(\\tau) g(t-\\tau) d\\tau$\n",
    "\n",
    "For images: matrix form --> feature detectors = Kernels = filters\n",
    "\n",
    "(Input Image * Feature Detector) = (Feature Map) [= convolved map, activation map,...]\n",
    "\n",
    "\n",
    "<img src=\"files/Convolution.png\">\n",
    "\n",
    "note that the size is reduced after the filter is applied.\n",
    "\n",
    "In the NN: different filter are applied to the original image --> creates feature maps.\n",
    "\n",
    "##### ReLU Layer\n",
    "\n",
    "After the convolution layer: a rectifier function layer $\\phi(x) = \\max(x,0)$ is added.\n",
    "Add non-linearity to the model.\n",
    "Only keep the important 'features' of an image after a filter is applied.\n",
    "\n",
    "for more info: \n",
    "\n",
    "Examples: http://mlss.tuebingen.mpg.de/2015/slides/fergus/Fergus_1.pdf\n",
    "\n",
    "C. - C. Jay Kuo (2016) - Understanding Convolutional Neural Networks with a Mathematical Model \n",
    "    https://arxiv.org/pdf/1609.04112.pdf\n",
    "\n",
    "Alternative to ReLU (parametric ReLU): \n",
    "\n",
    "Kaiming He et al.(2015) - Delving deep into rectifiers: surpassing human-level performance on ImageNet Classification\n",
    "https://arxiv.org/pdf/1502.01852.pdf\n",
    "\n",
    "\n",
    "#### (Max) Pooling\n",
    "\n",
    "Spatial invariance: features can be tilted, a bit distorted (rotated etc;) the network must still be able to recognise the feature.\n",
    "\n",
    "Feature map --> Pooled Feature Map\n",
    "\n",
    "<img src=\"files/max_pooling.png\">\n",
    "\n",
    "Large numbers represent largest \"features\", distrotion is removed from the image --> (images are simplified).\n",
    " - total image size is reduced.\n",
    " - overfitting is reduced (only the features are maintained).\n",
    " \n",
    "Different options for pooling:\n",
    "\n",
    "Dominik Scherer et al. (2010) - Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition\n",
    "http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf\n",
    "\n",
    "\n",
    "#### Flattening\n",
    "\n",
    "Change the matrix of the feature map to a vector. Which can be used as input to an ANN.\n",
    "\n",
    "\n",
    "\n",
    "#### Fully Connected Layer\n",
    "\n",
    "<img src=\"files/ANN_layer.png\">\n",
    "\n",
    "Fully connected ANN is created that combines the features to predict the output (classification).\n",
    "\n",
    "Backpropagation: through the ANN, and the CNN network to change the feature detectors.\n",
    "\n",
    "\n",
    "#### Softmax & Cross-Entropy\n",
    "\n",
    "During training: Need to find what neurons are important for a certain output value (e.g. dog).\n",
    "The output neurons need to 'learn' what nodes in the final hidden layer are usefull for a certain output (=voting).\n",
    "\n",
    "- Softmax (normalized exponential function), so the total chance of the output is 1.\n",
    "\n",
    "$ f_j(z) = \\frac{e^{z_j}}{\\sum_k e^{z_k}}$\n",
    "\n",
    "\n",
    "- Cross-entropy - cost function (loss function)\n",
    "\n",
    "$H(p,q) = - \\sum_x p(x) \\log{q(x)}$\n",
    "\n",
    "- p = true value \n",
    "- q = predicted value\n",
    "- x = a certain node\n",
    "\n",
    "Cost-function for assessing the network performance of a CNN. (also called the loss-function).\n",
    "\n",
    "Why cross-entropy over mse? \n",
    "\n",
    "- Small values --> gives problems with gradient backward propagation. Especially in the beginning of the algorithm. (Small adjustments in absolute terms can be huge in relative terms).\n",
    "\n",
    "To know more:\n",
    "Youtube video: the softmax output function by Jeffrey Hinton.\n",
    "\n",
    "Rob DiPietro (2016) - A friendly introduction to cross-entropy loss\n",
    "    https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/\n",
    "\n",
    "Peter Roelants (2016) - How to implement a neural network Intermezzo 2\n",
    "\n",
    "https://peterroelants.github.io/\n",
    "\n",
    "\n",
    "Keras documentation\n",
    "\n",
    "https://keras.io/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "#libraries\n",
    "%matplotlib notebook   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# - Set path - \n",
    "#convert to raw string and add an extra \\ to the end (not to escape the string)\n",
    "dir = (r'C:\\Users\\msfernandez\\Machine Learning A-Z\\Machine Learning A-Z Template Folder\\Part 8 - Deep Learning\\Section 40 - Convolutional Neural Networks (CNN)\\\\')\n",
    "os.chdir(dir)\n",
    "\n",
    "# - - - - - - - - - - - - - - \n",
    "# Part 1: Build the CNN\n",
    "# - - - - - - - - - - - - - -\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "    # Initialising the CNN\n",
    "    # - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "classifier = Sequential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\msfernandez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\msfernandez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "250/250 [==============================] - 339s 1s/step - loss: 0.6652 - acc: 0.5946 - val_loss: 0.5933 - val_acc: 0.6867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d8921ae80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "# 32 feature detections, with size (3,3).\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2))) #stride of 2 & max pooling.\n",
    "\n",
    "# Add a 2nd layer to improve the accuracy.\n",
    "# popular to double the number of filters to 64 in the 2nd layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu')) # convolution\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2))) # pooling\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))  # fully connected layer (dense)\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid')) # output layer\n",
    "\n",
    "    # Compiling the CNN\n",
    "    # - - - - - - - - - - - - - -\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) #binary outcome\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image augmentation, to prevent overfitting on the small set.\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 250, #number of unique samples/batch size = 8000/32.\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 62) #number of unique sampels/batch size = 2000/32\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
